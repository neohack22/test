{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b5ff50dbcd3d4213a02758bd001e1c6c": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_8dc8c91ba04042f5aad86c5a55b57d30",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Illustrating \u001b[38;2;114;156;31m\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:11\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Illustrating <span style=\"color: #729c1f; text-decoration-color: #729c1f\"></span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:11</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "8dc8c91ba04042f5aad86c5a55b57d30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1939bdd4f4441c8891ace41b56ec7d8": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_5463bff163d64a589c1abf441dfec53b",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Judging illustrated story \u001b[38;2;114;156;31m\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:03:42\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Judging illustrated story <span style=\"color: #729c1f; text-decoration-color: #729c1f\"></span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:03:42</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "5463bff163d64a589c1abf441dfec53b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neohack22/test/blob/master/christmas_story_generation_challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!--- @wandbcode{weaviate-paris-nov-2024} -->"
      ],
      "metadata": {
        "id": "UEAGps7DDiOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Welcome to the Weights & Biases Christmas story Weaving challenge\n",
        "\n",
        "###  Resources\n",
        "\n",
        "- Challenge instructions: [wandb.me/station-f](https://wandb.me/station-f)\n",
        "- Challenge starter code(this colab): [wandb.me/christmas-weaving](http://wandb.me/christmas-weaving)\n",
        "- Submissions and evaluations project: [wandb.me/paris_dashboard](https://wandb.me/paris_dashboard)\n",
        "- Weights & Biases Weave [docs](https://wandb.me/docs_paris)\n",
        "\n",
        "Please run all, including the last code black as it is what actually submits your work to the dashboard."
      ],
      "metadata": {
        "id": "tfgzfaNCC1LA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wal8RQrP5HhK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8c5f488-e6ba-452b-d7ca-ea1e8d4c73ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/389.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m\u001b[0m\u001b[91m\u001b[0m \u001b[32m389.1/389.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m389.5/389.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m315.7/315.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m325.8/325.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU openai fal-client weave"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OpenAI API Key: \")\n",
        "os.environ[\"FAL_KEY\"] = getpass.getpass(\"Enter FalAI API Key: \")"
      ],
      "metadata": {
        "id": "1M9WLf-N6t6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1db2da0e-7e5d-49b1-80ef-dbd7f7c8a803"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter OpenAI API Key: 路路路路路路路路路路\n",
            "Enter FalAI API Key: 路路路路路路路路路路\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import requests\n",
        "import tempfile\n",
        "import time\n",
        "from io import BytesIO\n",
        "from typing import Any, Callable, Dict, Optional, Union\n",
        "\n",
        "import fal_client\n",
        "import weave\n",
        "from openai import OpenAI\n",
        "from PIL import Image\n",
        "from pydantic import BaseModel\n",
        "from rich.progress import track"
      ],
      "metadata": {
        "id": "KgBeM6vm5lEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get your API key\n",
        "\n",
        "Create or log into your Weights & Biases (W&B) account at [https://wandb.ai](https://wandb.ai/?utm_source=event&utm_medium=demo&utm_campaign=weaviate_paris_nov_2024) and copy your API key from [here](https://wandb.ai/authorize/?utm_source=event&utm_medium=demo&utm_campaign=weaviate_paris_nov_2024)."
      ],
      "metadata": {
        "id": "HKsUi2SuDKzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weave.init(\"ml-colabs/christmas-weaving-challenge\")"
      ],
      "metadata": {
        "id": "N1QUFia97YdV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "a46776b0-5e31-4479-d7c4-d6daf922a40a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please login to Weights & Biases (https://wandb.ai/) to continue:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 路路路路路路路路路路\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged in as Weights & Biases user: agatamlyn.\n",
            "View Weave data at https://wandb.ai/ml-colabs/christmas-weaving-challenge/weave\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<weave.trace.weave_client.WeaveClient at 0x7cbf12c45ff0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def base64_encode_image(image: Image.Image) -> str:\n",
        "    byte_arr = BytesIO()\n",
        "    image.save(byte_arr, format=\"PNG\")\n",
        "    encoded_string = base64.b64encode(byte_arr.getvalue()).decode(\"utf-8\")\n",
        "    encoded_string = f\"data:image/png;base64,{encoded_string}\"\n",
        "    return str(encoded_string)\n",
        "\n",
        "def custom_weave_wrapper(name: str) -> Callable[[Callable], Callable]:\n",
        "    def wrapper(fn: Callable) -> Callable:\n",
        "        op = weave.op()(fn)\n",
        "        op.name = name  # type: ignore\n",
        "        return op\n",
        "\n",
        "    return wrapper"
      ],
      "metadata": {
        "id": "p0zAok8P8D2g",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Weave** is a lightweight toolkit for tracking and evaluating LLM applications, built by Weights & Biases.\n",
        "\n",
        "Our goal is to bring rigor, best-practices, and composability to the inherently experimental process of developing AI applications, without introducing cognitive overhead.\n",
        "\n",
        "Get started by decorating Python functions with @weave.op().\n"
      ],
      "metadata": {
        "id": "54ivPa5oD45D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Story(BaseModel):\n",
        "    paragraphs: list[str]\n",
        "\n",
        "\n",
        "class StoryGenerationModel(weave.Model):\n",
        "    model_name: str\n",
        "    system_prompt: Optional[str] = None\n",
        "\n",
        "    @weave.op()\n",
        "    def frame_messages(\n",
        "        self,\n",
        "        prompts: Union[str, list[str]],\n",
        "        history: Optional[list[dict[str, str]]] = None\n",
        "    ):\n",
        "        messages = []\n",
        "        if self.system_prompt:\n",
        "            messages.append({\"role\": \"system\", \"content\": self.system_prompt})\n",
        "        if history:\n",
        "            messages += history\n",
        "        prompts = [prompts] if isinstance(prompts, str) else prompts\n",
        "        messages += [{\"role\": \"user\", \"content\": prompt} for prompt in prompts]\n",
        "        return messages\n",
        "\n",
        "    @weave.op()\n",
        "    def predict(\n",
        "        self,\n",
        "        prompts: Union[str, list[str]],\n",
        "        history: Optional[list[dict[str, str]]] = None\n",
        "    ):\n",
        "        messages = self.frame_messages(prompts, history)\n",
        "        completion = OpenAI().beta.chat.completions.parse(\n",
        "            model=self.model_name, messages=messages, response_format=Story\n",
        "        )\n",
        "        return completion.choices[0].message.parsed"
      ],
      "metadata": {
        "id": "MnnPLGBbI5O9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "story_generation_model = StoryGenerationModel(model_name=\"gpt-4o-mini\")\n",
        "story = story_generation_model.predict(\n",
        "    prompts=\"Generate a 3 paragraph long story about Christmas.\"\n",
        ")"
      ],
      "metadata": {
        "id": "CHxB4uElOuhX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97e91ce9-bed4-4442-fb53-21e54b746487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " https://wandb.ai/ml-colabs/christmas-weaving-challenge/r/call/019369d9-b2ac-7c40-b4d2-150934e46d48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageGenerationModel(weave.Model):\n",
        "    model_name: str\n",
        "    inference_kwargs: dict[str, any] = {}\n",
        "\n",
        "    def download_image_to_pil(self, url):\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_file:\n",
        "            temp_file.write(response.content)\n",
        "            temp_filename = temp_file.name\n",
        "        try:\n",
        "            image = Image.open(temp_filename)\n",
        "        finally:\n",
        "            os.unlink(temp_filename)\n",
        "        return image\n",
        "\n",
        "    @weave.op()\n",
        "    def predict(self, prompt: str) -> Image.Image:\n",
        "        result = custom_weave_wrapper(\n",
        "            name=\"fal_client.subscribe\"\n",
        "        )(fal_client.subscribe)(\n",
        "            self.model_name,\n",
        "            arguments={\"prompt\": prompt, **self.inference_kwargs},\n",
        "        )\n",
        "        return self.download_image_to_pil(result[\"images\"][0][\"url\"])"
      ],
      "metadata": {
        "id": "PZYAk_7b7I-p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bbde1ab-4125-4d20-a4ce-f9f0efd25231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_generate_schema.py:547: UserWarning: <built-in function any> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_generation_model = ImageGenerationModel(model_name=\"fal-ai/flux/dev\")\n",
        "images = image_generation_model.predict(prompt=story.paragraphs[0])"
      ],
      "metadata": {
        "id": "TLuuV7-h76ft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c647b33a-38da-47b4-d741-3c02ef495511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " https://wandb.ai/ml-colabs/christmas-weaving-challenge/r/call/019369d9-ca44-70a2-86d8-5a791b00d0be\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class IllustratedStoryGenerator(weave.Model):\n",
        "    story_generation_model: StoryGenerationModel\n",
        "    image_generation_model: ImageGenerationModel\n",
        "\n",
        "    @weave.op()\n",
        "    def generate_story(\n",
        "        self,\n",
        "        prompts: Union[str, list[str]],\n",
        "        history: Optional[list[dict[str, str]]] = None\n",
        "    ) -> Story:\n",
        "        return self.story_generation_model.predict(\n",
        "            prompts=prompts, history=history\n",
        "        )\n",
        "\n",
        "    @weave.op()\n",
        "    def illustrate_story(self, story: Story) -> list[Image.Image]:\n",
        "        return [\n",
        "            image_generation_model.predict(prompt=paragraph)\n",
        "            for paragraph in track(\n",
        "                story.paragraphs, description=\"Illustrating\"\n",
        "            )\n",
        "        ]\n",
        "\n",
        "    @weave.op()\n",
        "    def predict(\n",
        "        self,\n",
        "        prompts: Union[str, list[str]],\n",
        "        history: Optional[list[dict[str, str]]] = None\n",
        "    ) -> list[dict[str, Union[str, Image.Image]]]:\n",
        "        story = self.generate_story(\n",
        "            prompts=prompts, history=history\n",
        "        )\n",
        "        generated_images = self.illustrate_story(story)\n",
        "        return [\n",
        "            {\"paragraph\": paragraph, \"image\": image}\n",
        "            for paragraph, image in zip(story.paragraphs, generated_images)\n",
        "        ]"
      ],
      "metadata": {
        "id": "0tO39ix3DpXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "illustrated_story_generation_model = IllustratedStoryGenerator(\n",
        "    story_generation_model=story_generation_model,\n",
        "    image_generation_model=image_generation_model,\n",
        ")\n",
        "\n",
        "illustrated_story = illustrated_story_generation_model.predict(\n",
        "    prompts=\"Generate a 3 paragraph long story about Christmas.\"\n",
        ")"
      ],
      "metadata": {
        "id": "qZbreI9cUlYd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51,
          "referenced_widgets": [
            "b5ff50dbcd3d4213a02758bd001e1c6c",
            "8dc8c91ba04042f5aad86c5a55b57d30"
          ]
        },
        "outputId": "caa50452-582c-441a-f38a-7e0c6ae9ba7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5ff50dbcd3d4213a02758bd001e1c6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " https://wandb.ai/ml-colabs/christmas-weaving-challenge/r/call/019369d9-daf9-7b33-a098-037833e77d6f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Run this cell to get your illustrated story judged by Father Christmas and submitted to the challenge dashboard\n",
        "class IllustrationScore(BaseModel):\n",
        "    story_alignment_score: float\n",
        "    christmass_alignment_score: float\n",
        "\n",
        "\n",
        "class StoryJudgementScore(BaseModel):\n",
        "    story_quality: float\n",
        "    christmass_alignment_score: float\n",
        "    explanation: str\n",
        "\n",
        "\n",
        "class IllustratedStoryJudgementScore(BaseModel):\n",
        "    story_judgement_score: StoryJudgementScore\n",
        "    illustration_score: IllustrationScore\n",
        "    final_score: float\n",
        "\n",
        "\n",
        "class FatherChristmas(weave.Model):\n",
        "    image_description_model_name: str = \"gpt-4o\"\n",
        "    judgement_model_name: str = \"gpt-4o\"\n",
        "\n",
        "    @weave.op()\n",
        "    def decribe_image(self, image: Image.Image) -> str:\n",
        "        completion = OpenAI().chat.completions.create(\n",
        "            model=self.image_description_model_name,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"\"\"\n",
        "You are a helpful assistant meant to describe images in detail.\n",
        "First you must give an overall overview describing the image in not more than\n",
        "2 sentences.\n",
        "Next, you must analyze the image step-by-step and describe the actions, events,\n",
        "objects and their relationships, and the overall color palette, mood, and vibe\n",
        "of the image.\"\"\"\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\n",
        "                            \"type\": \"image_url\",\n",
        "                            \"image_url\": {\"url\": base64_encode_image(image)},\n",
        "                        },\n",
        "                    ],\n",
        "                },\n",
        "            ],\n",
        "        )\n",
        "        return completion.choices[0].message.content\n",
        "\n",
        "    @weave.op()\n",
        "    def judge_story(self, story: str) -> StoryJudgementScore:\n",
        "        completion = OpenAI().beta.chat.completions.parse(\n",
        "            model=self.judgement_model_name,\n",
        "            response_format=StoryJudgementScore,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"\"\"\n",
        "You are a helpful assistant meant to judge the quality of a story and how\n",
        "accurately it aligns with the themes of christmass.\n",
        "\n",
        "Here are some visual clues with respect to how much the story is aligned with christmas:\n",
        "\n",
        "1. Santa Clause\n",
        "2. Snow\n",
        "3. Elfs\n",
        "4. Christmas tree\n",
        "5. presents\n",
        "6. happy humans\n",
        "7. ginger breads\n",
        "8. star\n",
        "9. snowman\n",
        "10. jingle bells\n",
        "\n",
        "You must give a chirstmas alignment score that is a fractional number between\n",
        "0 and 1 which corresponds to how many of the aforementioned visual clues are present.\n",
        "You must follow the following strategy for predicting the chirstmas alignment score:\n",
        "\n",
        "1. You must assign a score of 1.0 if all the visual clues are present in the story.\n",
        "2. You must assign a score of 0.9 if only 9 of the visual clues are present in the story.\n",
        "3. You must assign a score of 0.8 if only 8 of the visual clues are present in the story.\n",
        "4. You must assign a score of 0.7 if only 7 of the visual clues are present in the story.\n",
        "5. You must assign a score of 0.6 if only 6 of the visual clues are present in the story.\n",
        "6. You must assign a score of 0.5 if only 5 of the visual clues are present in the story.\n",
        "7. You must assign a score of 0.4 if only 4 of the visual clues are present in the story.\n",
        "8. You must assign a score of 0.3 if only 3 of the visual clues are present in the story.\n",
        "9. You must assign a score of 0.2 if only 2 of the visual clues are present in the story.\n",
        "10. You must assign a score of 0.1 if only 1 of the visual clues is present in the story.\n",
        "\n",
        "\n",
        "You must give a story quality score that is a fractional number between\n",
        "0 and 1 which corresponds to how creative and charmful the story is with respect\n",
        "to the motiff of Christmas. You must follow the following strategy for\n",
        "predicting the story alignment score:\n",
        "\n",
        "1. If there's not charm or magical Christmas spirit and the story feels dull\n",
        "    serious, or devoid of whimsy; you must assign a story quality score\n",
        "    in the range 0.0 to 0.25.\n",
        "2. If the story has some charm or magic but isnt fully inspired and only has a\n",
        "    few playful elements but doesn't evoke much joy; you must assign a\n",
        "    story quality score in the range 0.25 to 0.5.\n",
        "3. If the story has charm, magic, some festive cheer, and enough playful\n",
        "    elements to make an elf smile; you must assign a story quality score in the\n",
        "    range 0.5 to 0.75.\n",
        "4. If the story exudes charm, magic, and abundant festive cheer such that\n",
        "    it feels alive with holiday spirit and creativity, bringing a smile to any\n",
        "    elfs face; you must assign a story quality score in the range 0.75 to 1.0.\n",
        "\"\"\"\n",
        "                },\n",
        "                {\"role\": \"user\", \"content\": story},\n",
        "            ]\n",
        "        )\n",
        "        return completion.choices[0].message.parsed\n",
        "\n",
        "    @weave.op()\n",
        "    def judge_paragraph_illustration(\n",
        "        self, story: str, paragraph: str, image: Image.Image\n",
        "    ) -> IllustrationScore:\n",
        "        image_description = self.decribe_image(image)\n",
        "        completion = OpenAI().beta.chat.completions.parse(\n",
        "            model=self.judgement_model_name,\n",
        "            response_format=IllustrationScore,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"\"\"\n",
        "You are a helpful assistant meant to judge the quality of an image that has to\n",
        "be used as an illustration for a paragraph from a story about christmass.\n",
        "\n",
        "You will be provided the entire story within tags <story>...</story>.\n",
        "You will be provided the paragraph within tags <paragraph>...</paragraph>.\n",
        "You will be provided the illustration image corresponding to the paragraph.\n",
        "\n",
        "You are to closely refer to all the information provided to predict a\n",
        "fractional score call story alignment score (between 0 and 1) for the image on\n",
        "how well it aligns with the story in general and the paragraph in particular.\n",
        "You must follow the following strategy for predicting the christmass alignment score:\n",
        "1. If the image is of poor quality, with significant issues like blurriness,\n",
        "    distortions, or technical flaws; you must assign a story alignment score\n",
        "    in the range 0.0 to 0.25.\n",
        "2. If the image is of average quality, with some issues that detract from its appeal,\n",
        "    like blurriness or inconsistencies; you must assign a story alignment score\n",
        "    in the range 0.25 to 0.5.\n",
        "3. If the image is of good quality, polished, and visually appealing.\n",
        "    It demonstrates good technical skills, with minor issues.; you must assign\n",
        "    a story alignment score in the range 0.5 to 0.75.\n",
        "4. If The image is of high quality, visually striking, with attention to detail\n",
        "    and creativity. Its clear, well-composed, and aesthetically pleasing;\n",
        "    you must assign a story alignment score in the range 0.75 to 1.0.\n",
        "5. You must also compare the image with the story and deduct 0.2 point for\n",
        "    every missing visual clue.\n",
        "\n",
        "\n",
        "You must also predict a fractional score called christmass alignment score\n",
        "(between 0 and 1) for how well the image aligns visually with the idea of christmass.\n",
        "Here are some visual clues with respect to how much the story is aligned with christmas:\n",
        "\n",
        "1. Santa Clause\n",
        "2. Snow\n",
        "3. Elfs\n",
        "4. Christmas tree\n",
        "5. presents\n",
        "6. happy humans\n",
        "7. ginger breads\n",
        "8. star\n",
        "9. snowman\n",
        "10. jingle bells\n",
        "\n",
        "You must follow the following strategy for predicting the chirstmas alignment score:\n",
        "\n",
        "1. You must assign a score of 1.0 if all the visual clues are present in the story.\n",
        "2. You must assign a score of 0.9 if 9 of the visual clues are present in the story.\n",
        "3. You must assign a score of 0.8 if 8 of the visual clues are present in the story.\n",
        "...\n",
        "\"\"\"\n",
        "                },\n",
        "                {\"role\": \"user\", \"content\": f\"<story>\\n{story}\\n</story>.\"},\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": f\"<paragraph>\\n{paragraph}\\n</paragraph>.\"\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\n",
        "                            \"type\": \"image_url\",\n",
        "                            \"image_url\": {\"url\": base64_encode_image(image)},\n",
        "                        },\n",
        "                    ],\n",
        "                },\n",
        "            ],\n",
        "        )\n",
        "        return completion.choices[0].message.parsed\n",
        "\n",
        "    @weave.op()\n",
        "    def predict(\n",
        "        self, illustrated_story: list[dict[str, Union[str, Image.Image]]]\n",
        "    ) -> IllustratedStoryJudgementScore:\n",
        "        story = \"\\n\\n\".join([paragraph[\"paragraph\"] for paragraph in illustrated_story])\n",
        "        story_judgement_score = self.judge_story(story)\n",
        "        mean_illustration_score = IllustrationScore(\n",
        "            story_alignment_score=0, christmass_alignment_score=0\n",
        "        )\n",
        "        for illustrated_paragraph in track(illustrated_story, description=\"Judging illustrated story\"):\n",
        "            paragraph = illustrated_paragraph[\"paragraph\"]\n",
        "            image = illustrated_paragraph[\"image\"]\n",
        "            illustration_score = self.judge_paragraph_illustration(story, paragraph, image)\n",
        "            mean_illustration_score.story_alignment_score += illustration_score.story_alignment_score\n",
        "            mean_illustration_score.christmass_alignment_score += illustration_score.christmass_alignment_score\n",
        "        mean_illustration_score.story_alignment_score = mean_illustration_score.story_alignment_score / len(illustrated_story)\n",
        "        mean_illustration_score.christmass_alignment_score = mean_illustration_score.christmass_alignment_score / len(illustrated_story)\n",
        "        return IllustratedStoryJudgementScore(\n",
        "            story_judgement_score=story_judgement_score,\n",
        "            illustration_score=mean_illustration_score,\n",
        "            final_score=(story_judgement_score.story_quality + story_judgement_score.christmass_alignment_score + mean_illustration_score.story_alignment_score + mean_illustration_score.christmass_alignment_score) * 100 / 4\n",
        "        )\n",
        "\n",
        "\n",
        "judge = FatherChristmas()\n",
        "judgement = judge.predict(illustrated_story)"
      ],
      "metadata": {
        "id": "i02W4dT4U4QV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51,
          "referenced_widgets": [
            "f1939bdd4f4441c8891ace41b56ec7d8",
            "5463bff163d64a589c1abf441dfec53b"
          ]
        },
        "outputId": "76625baf-6247-4a29-f926-5cff747cd247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1939bdd4f4441c8891ace41b56ec7d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " https://wandb.ai/ml-colabs/christmas-weaving-challenge/r/call/019369da-1a3e-75b1-87cd-bdd728243790\n"
          ]
        }
      ]
    }
  ]
}